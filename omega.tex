
\documentclass{svjour3}                     % onecolumn (standard format)
\usepackage[spanish, english, activeacute]{babel} %Definir idioma español
\usepackage[utf8]{inputenc} %Codificacion utf-8
\usepackage[autostyle]{csquotes}

\begin{document}

\title{  Omega: flexible, scalable schedulers for large computer clusters  }

%\titlerunning{Short form of title}        % if too long for running head

\author{ Íñigo Mediavilla }
\institute{ UPMC Master STL \at
              \email{imediava@gmail.com}           %  \\
}

\date{\today}

\maketitle

\begin{abstract}
This article describes the scheduler called Omega developed by
engineers at Google. It starts by providing an introduction to the
main problems that the design of a scheduler has to face mainly the
diversity of scheduling strategies that the different applications
implement and that schedulers need to support while remaining capable
of taking scheduling quick enough to avoid delaying the execution of
jobs. Then it provides a description of the main alternatives that
have been proposed to this problems to finally explain the solution
advocated by Omega.
\keywords{Scala \and Reflection \and Macro }
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\section{Introduction}

\subsection{Importance of scheduling}

Scheduling is planning the execution of a
set of computations that we'll call jobs in an execution environment
with a limited amount of resources. Initially scheduling was studied
in the context of operating systems, however more recently with the
popularization (?) of datacenters a different range of scheduling
techniques are being applied for the allocation of resources in
clusters. 

Clusters can run both batch jobs and long running jobs (services), two
types of jobs that represent two completely different requirements.
The former requires most of the resources in a cluster however most of
the jobs executed in modern clusters (google, yahoo references) are
batch jobs with short timespan.

One can measure the good use of a cluster by considering if the
quality constraints required by services are satisfied, the execution
time of batch jobs and the percentage of cluster utilization. The
quality of the scheduling algorithm used for a cluster affects all
these metrics so having a good scheduling algorithm has a great
impact in terms of costs and quality of the services provided.

\subsection{Difficulties (Problematica) with cluster scheduling}

However the design of a cluster scheduler is not a straightforward
task since it has many (sometimes contradictory) requirements.

From now on we will call the applications that are executed in a cluster frameworks.
The number of frameworks for a given cluster can be high and the
requirements for every one of them completely different. For example,
service jobs needs are orthogonal to batch jobs needs and even
map-reduce jobs [ref] have different constraints than MPI [ref]
jobs despite both being used to basically process and transform
data.

These frameworks adopt different strategies to place the
execution of their tasks in the cluster but most of the
time they need to access the same data. Given that replicating the
data in independent clusters is an extremely expensive alternative, frameworks
need to be executed in the same cluster that needs to be able to adapt
to the specific needs of every application while avoiding conflicts in
the assignment of resources.

Schedulers need to be adapted to execute both batch jobs and services
two kind of jobs that as we have seen have completely different
requirements that sometimes conflict. Services need to be highly
available [ref] and provide low latency demanding most of the
resources of a cluster [ref] while batch jobs are composed of thousands of small
tasks that can be affected by small delays in the scheduler and that
operate over data stored in the cluster and should
preferably be executed in the node where the data is kept but that
provide a certain degree of flexibility to the scheduler because they
often allow preemption.

High availability is a requirement applicable to the schedulers
themselves whose downtime affects the execution of any job to be
scheduled, but also low latency is required as we have seen in the
case of the thousand of tasks that usually conform a batch
job. Availability and low latency become harder requirements as the
cluster grows, increasing the pressure on the scheduler that becomes
more prone to failure and to delays.

\subsection{Solutions for coordinated cluster scheduling}

In the following section we will explain some of the existing models
of cluster schedulers considering their advantages and disadvantages
having into account the criteria introduced in the previous
section. Finally we will introduce the model omega [ref] proposed by
engineers at google that aspires to overcome most of the
limitations of the other approaches.

\subsubsection{Centralized scheduler}

The first schedulers were designed following a monolithic architecture
with a central scheduler taking care of the distributing the execution
of jobs across the nodes of the cluster. This design has, at least in
the beginning, the advantage of being simple since there's only one
scheduler assigning resources as well as having knowledge about the
whole state of the cluster, what makes it capable of taking really
good scheduling decisions specially when all jobs have the same
scheduling requirements. Besides, this design provides a good
utilization of the resources of the cluster.

However this design that is simple and capable of taking good
decisions in the beginning, has many problems as the size of the
cluster increases or as the jobs executed in the cluster
diversify. When the number of jobs to execute increases, the central
scheduler needs to be able to keep with the pace of jobs that are
planned. On top of that a single scheduler represents a single point
of failure. Parallelization can atenuate both problems but just as the
cost of adding complexity and introducing the need for synchronization
between the schedulers.

But above all, for a centralized scheduler is difficult to adapt
adequately to the heterogeinity of jobs that is executed in today's
clusters [ref to google's trace]. Trying to define different
scheduling paths for the different types of workloads is difficult
because it requires algorithms to identify the type of a job, and comes
at the expense of the scheduler's complexity. Some schedulers try to
support different policies by implement really complex algorithms
involving different weighting factors that provide rough
approximations of the objectives of every kind of workload. Others
like google's run different scheduling logic for every kind of
workload but it usually implies that users of the scheduler need to
have a really good understanding of the internals of the scheduling
algorithm to be able to optimize the execution of jobs. In both cases
the solution implies an additional layer of complexity to an already
difficult task.

Besides this model requires modifying the code of the scheduler every
time a new type of workload appears. 



Pro:

- Control over the whole cluster (capable of taking good scheduling decisions)
- Good cluster utilization
- Simplest solution when there's only one framework running in the cluster

Problems:

- Single point of failure
- Doesn't scale (bottleneck)
- Can't adapt to new frameworks with new policies and needs
- Complexity
- It doesn't scale well when the cluster grows

\subsection{Static partitioning}

To overcome the limitations that the previous model had when dealing
with clusters where the categories of jobs have different scheduling
needs, static partitioning allows to split the resources of the cluster
in as many partitions as the number of categories of jobs that we want to
treat independently. This strategy is attractive because it allows to
have an optimized dedicated scheduler for every category while being
relatively simple since every scheduler manages its portion of the
cluster without any risk of conflicts with the others. It was
for a while the model chosen by companies like Yahoo [ref?].

Nonetheless this strategy's drawback is that since the different 
categories run in different, isolated portions of the cluster the
resources of the cluster are squandered since there exists no way for
a category to use the resources that another category is not utilizing.

Pros:

- Simple
- Every framework can use their specific scheduler that is specialized
- There's no possibility of conflicts between frameworks when
  accessing the resources

Cons:

- Difficult to decide what is the right partition of the resources
between frameworks
- Non-optimal utilization of the resources of the cluster, for example
if one of the frameworks is idle other framework cannot use those
available resources since the repartition is done statically

\subsection{Two-Level scheduler}

Better explanation of mesos:

Mesos provides a solution to the problem of scheduling that is based
on the fact that defining an scheduler to match the constraints of different
frameworks is difficult since the needs of these frameworks can be
extremely heterogenous. To avoid this problem mesos is a platform for
resource sharing where a master runs a set of frameworks. The master
offers the possibility to use the available resources to the frameworks
through offers that the frameworks can accept or reject considering if
the offered resources match the expectations of the framework. When
offers are accepted the scheduler of the framework provides
information about what tasks it want to run and what resources it will
take and the mesos master will run the tasks on the slaves and
continue to offer the available resources to the schedulers of the
other frameworks available in the cluster.

The partition of resources between frameworks is left to the master
that implements two simple policies, one based on fair resource
sharing (ref) and another on strict priorities.

(add diagram over how mesos works?)


Advantages:

- Really simple central scheduler (master in Mesos terms) that has
  failover 
- Flexible: every framework decides how it schedules its tasks, the
master only offers resources following fairness (explain what fairness is?)
- Through offer rejection, frameworks can achieve high data locality
only accepting offers that correspond to nodes where the data is
stored. To avoid waiting indefinitively a technique called delayed
scheduling (ref) has proved to achieve high data locality without
sacrificing job execution time benefiting from the fact that tasks in
data processing frameworks like hadoop or MPI are short so resources
are freed frequently.
- Scalability

Disadvantages:

- Difficult to place picky jobs, for example to do gang scheduling
frameworks in Mesos need to do resource hoarding what can lead to
deadlocks
- Optimistic locking, while a framework is offered some resources it
holds the lock for the resource for the time the offer is
available. For example if a framework holds the resources or takes the
time to respond all other frameworks that are actually ready to accept
the offer and execute the job will have to wait for the first
framework to respond to the offer.
- Framework scheduler written in an indirect style (adapt to the interface, 
  take actions only when the resources are offered in an indirect away unlike
  the direct style given by optimistic locking

\subsection{Optimistic locking}

Another approach to cluster scheduling that tries to overcome some of
the limitations of the pessimistic locking of two-level schedulers is
the optimistic locking approach proposed by google's Omega
scheduler.

The idea behind optimistic locking is to make the state of the cluster
available to every framework's scheduler. When one of the framework's
wants to run a job in the cluster it tries to commit a lock for the
resources needed to run the task of the job. If the tasks has already
been taken by another framework since the last update of the cluster's
state, the framework receives the updated version of the cluster's
state and it can retry a commit knowing the new state of the cluster.

Glossary

- Frameworks (distributed application)
- Job
- Task
- Data locality

\end{document}
